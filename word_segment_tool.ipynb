{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 搭建一个分词工具\n",
    "\n",
    "### 基于枚举方法来搭建中文分词工具\n",
    "\n",
    "此项目需要的数据，[现代汉语常用词表.txt](https://github.com/liangqi/chinese-frequency-word-list)： \n",
    "1. 包含了中文词，当做词典来用\n",
    "2. 提供了词频，相当于可以变相得到unigram概率 word_prob\n",
    "\n",
    "\n",
    "举个例子： 给定词典=[我们 学习 人工 智能 人工智能 未来 是]， 另外我们给定unigram概率：p(我们)=0.25, p(学习)=0.15, p(人工)=0.05, p(智能)=0.1, p(人工智能)=0.2, p(未来)=0.1, p(是)=0.15\n",
    "\n",
    "#### Step 1: 对于给定字符串：”我们学习人工智能，人工智能是未来“, 找出所有可能的分割方式\n",
    "- [我们，学习，人工智能，人工智能，是，未来]\n",
    "- [我们，学习，人工，智能，人工智能，是，未来]\n",
    "- [我们，学习，人工，智能，人工，智能，是，未来]\n",
    "- [我们，学习，人工智能，人工，智能，是，未来]\n",
    ".......\n",
    "\n",
    "\n",
    "#### Step 2: 我们也可以计算出每一个切分之后句子的概率\n",
    "- p(我们，学习，人工智能，人工智能，是，未来)= -log p(我们)-log p(学习)-log p(人工智能)-log p(人工智能)-log p(是)-log p(未来)\n",
    "- p(我们，学习，人工，智能，人工智能，是，未来)=-log p(我们)-log p(学习)-log p(人工)-log p(智能)-log p(人工智能)-log p(是)-log p(未来)\n",
    "- p(我们，学习，人工，智能，人工，智能，是，未来)=-log p(我们)-log p(学习)-log p(人工)-log p(智能)-log p(人工)-log p(智能)-log p(是)-log p(未来)\n",
    "- p(我们，学习，人工智能，人工，智能，是，未来)=-log p(我们)-log p(学习)-log p(人工智能)-log p(人工)-log p(智能)-log(是)-log p(未来)\n",
    ".....\n",
    "\n",
    "#### Step 3: 返回第二步中概率最大的结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: 第一步： 现代汉语常用词表.txt中读取所有中文词及对应频率。\n",
    "from collections import Counter\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "with open('./data/现代汉语常用词表.txt') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "sum = 0\n",
    "word_prob = Counter()\n",
    "\n",
    "for line in lines:\n",
    "    columns = line.strip().split()\n",
    "    # 重复词频率直接相加，（相同词多次出现是因为发音不同，即语义也不同，这里不做区分）\n",
    "    word_prob[columns[0]] += int(columns[-1])\n",
    "    sum += int(columns[-1])\n",
    "\n",
    "# 频率转为概率\n",
    "for word in word_prob:\n",
    "    word_prob[word] /= sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'高个儿': 1.8414889771925325e-05}, {'传送带': 2.20334194331537e-05}, {'调遣': 1.4040430031872929e-05}]\n",
      "词典大小：55735\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# 测试\n",
    "print([{word: word_prob[word]} for word in random.sample(word_prob.keys(), 3)])\n",
    "print(\"词典大小：%d\" % len(word_prob))\n",
    "print(np.sum(list(word_prob.values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO 根据词典获得一句话的全切分，暂不考虑标点等\n",
    "def sentence_break(str):\n",
    "    \"\"\"\n",
    "    求该句话在当前词典下的全切分。\n",
    "    思路：状态转移，设M[i]是从句子开始到第i个字所组成句的全切分，word是以字i结尾的可在词典中找到的词，则M[i] = M[i-len(word)] + word\n",
    "    \n",
    "    str: 字符串，传入的句子\n",
    "    \"\"\"\n",
    "    \n",
    "    # 存储状态\n",
    "    memory = [[] for _ in range(len(str))]\n",
    "    # 更新memory[0]状态\n",
    "    if str[0] in word_prob:\n",
    "        memory[0].append([str[0]])\n",
    "    \n",
    "    for i in range(1, len(str)):\n",
    "        for j in range(0, i+1):\n",
    "            # 从开始到当前cursor视为一个词\n",
    "            if j == 0:\n",
    "                if str[j:i+1] in word_prob:\n",
    "                    memory[i].append([str[j:i+1]])\n",
    "                continue\n",
    "            # 确定依赖的之前状态存在且（达成转移条件：词存在）\n",
    "            if memory[j-1] and str[j:i+1] in word_prob:\n",
    "                # 状态转移过程\n",
    "                for state in memory[j-1]:\n",
    "                    memory[i].append(state + [str[j:i+1]])\n",
    "\n",
    "    return memory[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['北京', '的', '天气', '真', '好', '啊'], ['北', '京', '的', '天气', '真', '好', '啊'], ['北京', '的', '天', '气', '真', '好', '啊'], ['北', '京', '的', '天', '气', '真', '好', '啊']]\n",
      "[['今天', '的', '课程', '内容', '很', '有意思'], ['今', '天', '的', '课程', '内容', '很', '有意思'], ['今天', '的', '课', '程', '内容', '很', '有意思'], ['今', '天', '的', '课', '程', '内容', '很', '有意思'], ['今天', '的', '课程', '内', '容', '很', '有意思'], ['今', '天', '的', '课程', '内', '容', '很', '有意思'], ['今天', '的', '课', '程', '内', '容', '很', '有意思'], ['今', '天', '的', '课', '程', '内', '容', '很', '有意思'], ['今天', '的', '课程', '内容', '很', '有', '意思'], ['今', '天', '的', '课程', '内容', '很', '有', '意思'], ['今天', '的', '课', '程', '内容', '很', '有', '意思'], ['今', '天', '的', '课', '程', '内容', '很', '有', '意思'], ['今天', '的', '课程', '内', '容', '很', '有', '意思'], ['今', '天', '的', '课程', '内', '容', '很', '有', '意思'], ['今天', '的', '课', '程', '内', '容', '很', '有', '意思'], ['今', '天', '的', '课', '程', '内', '容', '很', '有', '意思'], ['今天', '的', '课程', '内容', '很', '有意', '思'], ['今', '天', '的', '课程', '内容', '很', '有意', '思'], ['今天', '的', '课', '程', '内容', '很', '有意', '思'], ['今', '天', '的', '课', '程', '内容', '很', '有意', '思'], ['今天', '的', '课程', '内', '容', '很', '有意', '思'], ['今', '天', '的', '课程', '内', '容', '很', '有意', '思'], ['今天', '的', '课', '程', '内', '容', '很', '有意', '思'], ['今', '天', '的', '课', '程', '内', '容', '很', '有意', '思'], ['今天', '的', '课程', '内容', '很', '有', '意', '思'], ['今', '天', '的', '课程', '内容', '很', '有', '意', '思'], ['今天', '的', '课', '程', '内容', '很', '有', '意', '思'], ['今', '天', '的', '课', '程', '内容', '很', '有', '意', '思'], ['今天', '的', '课程', '内', '容', '很', '有', '意', '思'], ['今', '天', '的', '课程', '内', '容', '很', '有', '意', '思'], ['今天', '的', '课', '程', '内', '容', '很', '有', '意', '思'], ['今', '天', '的', '课', '程', '内', '容', '很', '有', '意', '思']]\n",
      "[['经常', '有', '意见', '分歧'], ['经', '常', '有', '意见', '分歧'], ['经常', '有意', '见', '分歧'], ['经', '常', '有意', '见', '分歧'], ['经常', '有', '意', '见', '分歧'], ['经', '常', '有', '意', '见', '分歧']]\n"
     ]
    }
   ],
   "source": [
    "# 测试\n",
    "print(sentence_break(\"北京的天气真好啊\"))\n",
    "print(sentence_break(\"今天的课程内容很有意思\"))\n",
    "print(sentence_break(\"经常有意见分歧\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
